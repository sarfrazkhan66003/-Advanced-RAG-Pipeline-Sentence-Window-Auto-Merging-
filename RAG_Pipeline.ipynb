{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"api key\",\n",
    "    base_url=\"https://api.openai.com/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY = None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#print(\"OPENAI_API_KEY =\", os.environ.get(\"OPENAI_API_KEY\"))\n",
    "print(\"GROQ_API_KEY =\", os.environ.get(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (2026.1.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from huggingface_hub[hf_xet]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from huggingface_hub[hf_xet]) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub[hf_xet])\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2026.1.4)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.0/2.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 4.1 MB/s  0:00:00\n",
      "Installing collected packages: hf-xet\n",
      "Successfully installed hf-xet-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install openai\n",
    "#%pip install llama-index\n",
    "# %pip install pypdf\n",
    "# %pip install langchain\n",
    "# %pip install transformers\n",
    "# %pip install pymupdf\n",
    "# %pip install sentence-transformers\n",
    "# %pip install faiss-cpu\n",
    "# %pip install -U pypdf pymupdf\n",
    "# %pip install openai llama-index langchain transformers sentence-transformers faiss-cpu\n",
    "#%pip install llama-index-llms-groq\n",
    "#%pip install -U llama-index-core llama-index-readers-file pypdf pymupdf\n",
    "%pip install huggingface_hub[hf_xet]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "Settings.llm = Groq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    api_key=\"api key\",\n",
    "    base_url=\"https://api.openai.com/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:36:39,926 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2026-01-15 19:36:45,179 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"api key\"] = \"sk-...\"  # Apna actual key yahan daalo\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0.1)\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = 'local:BAAI/bge-small-en-v1.5'\n",
    "\n",
    "index = VectorStoreIndex.from_documents([document])\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load PDF with PyMuPDFReader...\n",
      "Number of documents: 4\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.core import SimpleDirectoryReader\n",
    "# from llama_index.readers.file import PDFReader\n",
    "\n",
    "# documents = SimpleDirectoryReader(\n",
    "#     input_files=[\n",
    "#         r\"C:\\Users\\DELL\\OneDrive\\Desktop\\Sarfraz\\PW Data Science\\Project\\RAG_Application_Using_LLM\\Medical_Cost_Prediction.pdf\"\n",
    "#     ],\n",
    "#     file_extractor={\n",
    "#         \".pdf\": PDFReader()\n",
    "#     }\n",
    "# ).load_data()\n",
    "# print(f\"Number of documents: {len(documents)}\")\n",
    "\n",
    "\n",
    "import traceback\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "try:\n",
    "    print(\"Attempting to load PDF with PyMuPDFReader...\")\n",
    "    documents = SimpleDirectoryReader(\n",
    "        input_files=[\n",
    "            r\"C:\\Users\\DELL\\OneDrive\\Desktop\\Sarfraz\\PW Data Science\\Project\\RAG_Application_Using_LLM\\Medical_Cost_Prediction.pdf\"\n",
    "        ],\n",
    "        file_extractor={\n",
    "            \".pdf\": PyMuPDFReader()\n",
    "        },\n",
    "        raise_on_error=True\n",
    "    ).load_data()\n",
    "    print(f\"Number of documents: {len(documents)}\")\n",
    "except Exception:\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "4 \n",
      "\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "Doc ID: c4d2f10f-d942-4dc0-b359-e2747d7b5619\n",
      "Text: 11/28/23, 11:00 PM README.md - Grip localhost:6419 1/4 README.md\n",
      "Medical Cost Prediction Predicting medical costs of individuals based\n",
      "on different features using several ML (Regression) algorithms. The\n",
      "application was deployed on AWS EC2 through AWS ECR (Dockerized\n",
      "Container). Dataset The Medical Cost Prediction consists of around\n",
      "1300 records ...\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline includes three components: Ingestion -> Retrieval -> Synthesis\n",
    "\n",
    "##### **Ingestion**: Documents are divided into chunks -> chuncks are embedded using embedding model -> the embeddings are stored in a Vector Store Index\n",
    "##### **Retrieval**: User's query is matched with the embeddings of chunks in index -> Top K chunks are taken out that match the embeddings of the query\n",
    "##### **Synthesis**: K chunks taken in the previous component are combined with the user's query -> Combined text (embeddings) is sent to the LLM for its response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded: 3698 characters\n"
     ]
    }
   ],
   "source": [
    "from rag_helpers import get_merged_document\n",
    "\n",
    "# Load and merge your PDF in one line\n",
    "document = get_merged_document(\n",
    "    r\"C:\\Users\\DELL\\OneDrive\\Desktop\\Sarfraz\\PW Data Science\\Project\\RAG_Application_Using_LLM\\Medical_Cost_Prediction.pdf\"\n",
    ")\n",
    "print(f\"Document loaded: {len(document.text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n"
     ]
    }
   ],
   "source": [
    "from rag_helpers import load_pdf_documents, merge_documents\n",
    "\n",
    "# Load documents\n",
    "documents = load_pdf_documents(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\Sarfraz\\PW Data Science\\Project\\RAG_Application_Using_LLM\\Medical_Cost_Prediction.pdf\")\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "# Merge them\n",
    "document = merge_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the elements in the documents above\n",
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text='\\n\\n'.join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_helpers import merge_documents\n",
    "\n",
    "document = merge_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 4\n",
      "Merged document length: 3698 characters\n"
     ]
    }
   ],
   "source": [
    "from rag_helpers import load_pdf_documents, merge_documents\n",
    "\n",
    "# Load PDF documents\n",
    "documents = load_pdf_documents(\n",
    "    r\"C:\\Users\\DELL\\OneDrive\\Desktop\\Sarfraz\\PW Data Science\\Project\\RAG_Application_Using_LLM\\Medical_Cost_Prediction.pdf\"\n",
    ")\n",
    "print(f\"Number of documents: {len(documents)}\")\n",
    "\n",
    "# Merge into single document\n",
    "document = merge_documents(documents)\n",
    "print(f\"Merged document length: {len(document.text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:32:44,950 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2026-01-15 19:32:50,353 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Index created successfully!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Configure LLM\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0.1)\n",
    "\n",
    "# Set global settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = 'local:BAAI/bge-small-en-v1.5'\n",
    "\n",
    "# Create index\n",
    "index = VectorStoreIndex.from_documents([document])\n",
    "\n",
    "print(\"✅ Index created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Document' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Merging the elements in the documents above\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m      5\u001b[0m document \u001b[38;5;241m=\u001b[39m Document(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]))\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Document' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Merging the elements in the documents above\n",
    "from llama_index import Document\n",
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text='\\n\\n'.join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:34:46,061 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2026-01-15 19:34:51,098 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "# Vector Store Index is used to store the chunks (from documents), text (chunk's text), and their corresponding embeddings\n",
    "# Settings is used to configure the LLM and embedding model (ServiceContext is deprecated in v0.10+)\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0.1)\n",
    "\n",
    "# Set global settings (NEW way - ServiceContext is deprecated)\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = 'local:BAAI/bge-small-en-v1.5'\n",
    "\n",
    "# Create index - Settings will be used automatically\n",
    "index = VectorStoreIndex.from_documents([document])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing query engine from the above index that allows us to send user's query to the **synthesis** component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"api key\"] = \"sk-...\"  # Apna actual key yahan daalo\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0.1)\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = 'local:BAAI/bge-small-en-v1.5'\n",
    "\n",
    "index = VectorStoreIndex.from_documents([document])\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:39:32,840 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2026-01-15 19:39:40,199 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"api key\"  # Apna Groq API key yahan daalo\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "Settings.llm = Groq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "Settings.embed_model = 'local:BAAI/bge-small-en-v1.5'\n",
    "\n",
    "index = VectorStoreIndex.from_documents([document])\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:39:50,377 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2026-01-15 19:39:54,927 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api key\"  # Apna OpenAI API key yahan daalo\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "Settings.llm = OpenAI(model='gpt-3.5-turbo', temperature=0.1, api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "Settings.embed_model = 'local:BAAI/bge-small-en-v1.5'\n",
    "\n",
    "index = VectorStoreIndex.from_documents([document])\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 20:24:34,701 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2026-01-15 20:24:38,409 - INFO - 1 prompt is loaded, with the key: query\n",
      "2026-01-15 20:24:39,307 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The project is deployed using AWS ECR and AWS EC2. To deploy, a Docker image is created and checked locally. Then, workflows are added to the GitHub repository, and the appropriate deployment method is chosen. An IAM User is created with necessary policies, and access keys are generated. An ECR repository is created, and an EC2 instance is set up with the necessary packages for Docker. The runner is set up on the EC2 instance, and secret keys are created in GitHub Actions.\n"
     ]
    }
   ],
   "source": [
    "# Groq API key set karo\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"api key\"\n",
    "\n",
    "# Index banate waqt Groq LLM use karo\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "Settings.llm = Groq(\n",
    "    model=\"llama-3.3-70b-versatile\",  # LATEST working model (Jan 2026)\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "Settings.embed_model = 'local:BAAI/bge-small-en-v1.5'\n",
    "\n",
    "# Index create karo\n",
    "index = VectorStoreIndex.from_documents([document])\n",
    "\n",
    "# Query engine banao\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Ab query karo\n",
    "response = query_engine.query('How is the project deployed')\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 20:24:44,513 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The project is deployed using AWS ECR and AWS EC2. To deploy, a docker image is created and checked locally. Then, workflows are added to the GitHub repository, and the appropriate deployment method is chosen. An IAM User is created with necessary policies, and access keys are generated. A new ECR repository is created, and an EC2 instance is set up with necessary packages for docker. The runner is then set up on the EC2 instance, and secret keys are created in GitHub Actions.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('How is the project deployed')\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TruLens is a software tool that helps you to objectively measure the quality and effectiveness of your LLM-based applications using feedback functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the technologies used in the project?\n",
      "What is the installation process?\n",
      "Can you talk about the dataset used in the project?\n",
      "Can you explain the usage of the project?\n",
      "What is the process of deployment used in the project?\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt','r') as file:\n",
    "    for line in file:\n",
    "        # Removing new line character and converting it to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 20:43:13,101 - INFO - Context impl SQLiteImpl.\n",
      "2026-01-15 20:43:13,105 - INFO - Will assume non-transactional DDL.\n",
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru, TruLlama\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trulens-eval\n",
      "  Using cached trulens_eval-2.5.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting trulens-core<3.0.0,>=2.0.0 (from trulens-eval)\n",
      "  Using cached trulens_core-2.5.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting trulens-dashboard<3.0.0,>=2.0.0 (from trulens-eval)\n",
      "  Using cached trulens_dashboard-2.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting trulens-feedback<3.0.0,>=2.0.0 (from trulens-eval)\n",
      "  Using cached trulens_feedback-2.5.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic<2.0.0,>=1.8.1 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached alembic-1.18.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting dill<0.4.0,>=0.3.8 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting importlib-resources<7.0,>=6.0 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: munch<3.0.0,>=2.5.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0,>=1.5 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.2.6)\n",
      "Collecting opentelemetry-api>=1.23.0 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto>=1.23.0 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.23.0 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging>=23.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (25.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.3.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv<2.0,>=0.21 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (1.2.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.32.5)\n",
      "Collecting rich<14.0.0,>=13.6.0 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sqlalchemy<3.0,>=2.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.0.45)\n",
      "Collecting trulens-otel-semconv<3.0.0,>=2.0.0 (from trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached trulens_otel_semconv-2.5.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.9 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.17.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-eval) (1.17.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from alembic<2.0.0,>=1.8.1->trulens-core<3.0.0,>=2.0.0->trulens-eval) (1.3.10)\n",
      "Requirement already satisfied: tomli in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from alembic<2.0.0,>=1.8.1->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from munch<3.0.0,>=2.5.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (1.17.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.4.2->trulens-core<3.0.0,>=2.0.0->trulens-eval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.4.2->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.4.2->trulens-core<3.0.0,>=2.0.0->trulens-eval) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests<3.0,>=2.31->trulens-core<3.0.0,>=2.0.0->trulens-eval) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests<3.0,>=2.31->trulens-core<3.0.0,>=2.0.0->trulens-eval) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests<3.0,>=2.31->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from requests<3.0,>=2.31->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2026.1.4)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.6.0->trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from rich<14.0.0,>=13.6.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from sqlalchemy<3.0,>=2.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (3.3.0)\n",
      "Collecting ipywidgets>=7.1.2 (from trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyter<2,>=1 (from trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: plotly<6.0.0,>=5.22.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (5.24.1)\n",
      "Requirement already satisfied: psutil<6.0,>=5.9 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (5.9.8)\n",
      "Collecting streamlit<2.0,>=1.35 (from trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached streamlit-1.53.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: traitlets<6.0.0,>=5.0.5 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (5.14.3)\n",
      "Collecting notebook (from jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached notebook-7.5.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (7.0.1)\n",
      "Collecting jupyterlab (from jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyterlab-4.5.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from plotly<6.0.0,>=5.22.0->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (9.1.2)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<7,>=4.0 (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached altair-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=5.5 (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (8.3.1)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (12.1.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (6.33.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (22.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (6.0.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.1.6)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: narwhals>=1.27.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (2.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from click<9,>=7.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.0.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from pandas>=1.0.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from pandas>=1.0.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (2025.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-feedback<3.0.0,>=2.0.0->trulens-eval) (3.9.2)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-feedback<3.0.0,>=2.0.0->trulens-eval) (1.7.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.11.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from trulens-feedback<3.0.0,>=2.0.0->trulens-eval) (1.15.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->trulens-feedback<3.0.0,>=2.0.0->trulens-eval) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->trulens-feedback<3.0.0,>=2.0.0->trulens-eval) (2026.1.14)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->trulens-feedback<3.0.0,>=2.0.0->trulens-eval) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from scikit-learn<2.0.0,>=1.3.0->trulens-feedback<3.0.0,>=2.0.0->trulens-eval) (3.6.0)\n",
      "Collecting opentelemetry-semantic-conventions>=0.36b0 (from trulens-otel-semconv<3.0.0,>=2.0.0->trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (8.37.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.0.16)\n",
      "Requirement already satisfied: decorator in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.0.52)\n",
      "Requirement already satisfied: stack_data in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (25.4.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit<2.0,>=1.35->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.30.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (0.1.2)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.23.0->trulens-core<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.23.0->trulens-core<3.0.0,>=2.0.0->trulens-eval) (3.23.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.8.17)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (27.1.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (4.5.0)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.28.1)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (80.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.16.0)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyter_server_terminals-0.5.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.24.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.0.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (2.1.0)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.9.0)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached json5-0.13.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-win_amd64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.1.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.0.0)\n",
      "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: uri-template in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (4.14.3)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.7.1)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.2.0)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached nbclient-0.10.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (2.21.2)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (1.3.1)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached cffi-2.0.0-cp310-cp310-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (2.23)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\dell\\onedrive\\desktop\\sarfraz\\pw data science\\project\\rag_application_using_llm\\venv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (2.8.1)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval)\n",
      "  Using cached arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.1.2->trulens-dashboard<3.0.0,>=2.0.0->trulens-eval) (0.2.3)\n",
      "Using cached trulens_eval-2.5.2-py3-none-any.whl (38 kB)\n",
      "Using cached trulens_core-2.5.2-py3-none-any.whl (287 kB)\n",
      "Using cached alembic-1.18.1-py3-none-any.whl (260 kB)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached trulens_dashboard-2.5.2-py3-none-any.whl (1.1 MB)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached streamlit-1.53.0-py3-none-any.whl (9.1 MB)\n",
      "Using cached altair-6.0.0-py3-none-any.whl (795 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
      "Using cached gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached trulens_feedback-2.5.2-py3-none-any.whl (65 kB)\n",
      "Using cached trulens_otel_semconv-2.5.2-py3-none-any.whl (5.6 kB)\n",
      "Using cached ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Using cached jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Using cached importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Using cached opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "Using cached opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached jupyterlab-4.5.2-py3-none-any.whl (12.4 MB)\n",
      "Using cached jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "Using cached jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "Using cached json5-0.13.0-py3-none-any.whl (36 kB)\n",
      "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Using cached jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "Using cached jupyter_server_terminals-0.5.4-py3-none-any.whl (13 kB)\n",
      "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Using cached bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "Using cached nbclient-0.10.4-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-win_amd64.whl (31 kB)\n",
      "Using cached cffi-2.0.0-cp310-cp310-win_amd64.whl (182 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached notebook-7.5.2-py3-none-any.whl (14.5 MB)\n",
      "Installing collected packages: terminado, rfc3987-syntax, referencing, opentelemetry-proto, markdown-it-py, jupyterlab-pygments, json5, importlib-resources, importlib-metadata, gitdb, fqdn, dill, cffi, cachetools, blinker, bleach, babel, async-lru, rich, pydeck, opentelemetry-api, jupyter-server-terminals, jsonschema-specifications, gitpython, arrow, argon2-cffi-bindings, alembic, opentelemetry-semantic-conventions, jsonschema, isoduration, ipywidgets, argon2-cffi, trulens-otel-semconv, opentelemetry-sdk, nbformat, jupyter-console, altair, trulens-core, streamlit, nbclient, jupyter-events, trulens-feedback, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter, trulens-dashboard, trulens-eval\n",
      "\n",
      "   - --------------------------------------  2/52 [referencing]\n",
      "   --- ------------------------------------  4/52 [markdown-it-py]\n",
      "   --- ------------------------------------  4/52 [markdown-it-py]\n",
      "   --- ------------------------------------  5/52 [jupyterlab-pygments]\n",
      "   ----- ----------------------------------  7/52 [importlib-resources]\n",
      "   ------ ---------------------------------  8/52 [importlib-metadata]\n",
      "   -------- ------------------------------- 11/52 [dill]\n",
      "   -------- ------------------------------- 11/52 [dill]\n",
      "   --------- ------------------------------ 12/52 [cffi]\n",
      "   ----------- ---------------------------- 15/52 [bleach]\n",
      "   ----------- ---------------------------- 15/52 [bleach]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------ --------------------------- 16/52 [babel]\n",
      "   ------------- -------------------------- 18/52 [rich]\n",
      "   ------------- -------------------------- 18/52 [rich]\n",
      "   ------------- -------------------------- 18/52 [rich]\n",
      "   ------------- -------------------------- 18/52 [rich]\n",
      "   ------------- -------------------------- 18/52 [rich]\n",
      "   -------------- ------------------------- 19/52 [pydeck]\n",
      "   -------------- ------------------------- 19/52 [pydeck]\n",
      "   -------------- ------------------------- 19/52 [pydeck]\n",
      "   --------------- ------------------------ 20/52 [opentelemetry-api]\n",
      "   ----------------- ---------------------- 23/52 [gitpython]\n",
      "   ------------------ --------------------- 24/52 [arrow]\n",
      "   -------------------- ------------------- 26/52 [alembic]\n",
      "   -------------------- ------------------- 26/52 [alembic]\n",
      "   ----------------- --------------- 27/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------- --------------- 27/52 [opentelemetry-semantic-conventions]\n",
      "   --------------------- ------------------ 28/52 [jsonschema]\n",
      "   ---------------------- ----------------- 29/52 [isoduration]\n",
      "   ----------------------- ---------------- 30/52 [ipywidgets]\n",
      "   ------------------------- -------------- 33/52 [opentelemetry-sdk]\n",
      "   -------------------------- ------------- 34/52 [nbformat]\n",
      "   --------------------------- ------------ 36/52 [altair]\n",
      "   --------------------------- ------------ 36/52 [altair]\n",
      "   --------------------------- ------------ 36/52 [altair]\n",
      "   --------------------------- ------------ 36/52 [altair]\n",
      "   ---------------------------- ----------- 37/52 [trulens-core]\n",
      "   ---------------------------- ----------- 37/52 [trulens-core]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ----------------------------- ---------- 38/52 [streamlit]\n",
      "   ------------------------------- -------- 41/52 [trulens-feedback]\n",
      "   -------------------------------- ------- 42/52 [nbconvert]\n",
      "   --------------------------------- ------ 43/52 [jupyter-server]\n",
      "   --------------------------------- ------ 43/52 [jupyter-server]\n",
      "   --------------------------------- ------ 43/52 [jupyter-server]\n",
      "   ----------------------------------- ---- 46/52 [jupyter-lsp]\n",
      "   ----------------------------------- ---- 46/52 [jupyter-lsp]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 47/52 [jupyterlab]\n",
      "   ------------------------------------ --- 48/52 [notebook]\n",
      "   ------------------------------------ --- 48/52 [notebook]\n",
      "   ------------------------------------ --- 48/52 [notebook]\n",
      "   ------------------------------------ --- 48/52 [notebook]\n",
      "   ------------------------------------ --- 48/52 [notebook]\n",
      "   ------------------------------------ --- 48/52 [notebook]\n",
      "   ------------------------------------ --- 48/52 [notebook]\n",
      "   -------------------------------------- - 50/52 [trulens-dashboard]\n",
      "   ---------------------------------------  51/52 [trulens-eval]\n",
      "   ---------------------------------------- 52/52 [trulens-eval]\n",
      "\n",
      "Successfully installed alembic-1.18.1 altair-6.0.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 async-lru-2.0.5 babel-2.17.0 bleach-6.3.0 blinker-1.9.0 cachetools-6.2.4 cffi-2.0.0 dill-0.3.9 fqdn-1.5.1 gitdb-4.0.12 gitpython-3.1.46 importlib-metadata-8.7.1 importlib-resources-6.5.2 ipywidgets-8.1.8 isoduration-20.11.0 json5-0.13.0 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.4 jupyterlab-4.5.2 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 markdown-it-py-4.0.0 nbclient-0.10.4 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.5.2 notebook-shim-0.2.4 opentelemetry-api-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 pydeck-0.9.1 referencing-0.37.0 rfc3987-syntax-1.1.0 rich-13.9.4 streamlit-1.53.0 terminado-0.18.1 trulens-core-2.5.2 trulens-dashboard-2.5.2 trulens-eval-2.5.2 trulens-feedback-2.5.2 trulens-otel-semconv-2.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install trulens-eval --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_4328\\1258527641.py:8: DeprecationWarning: Tru is deprecated, use TruSession instead.\n",
      "  tru = Tru()\n",
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.embeddings.multi_modal_base.MultiModalEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'tuple'> for base <class 'tuple'>\n",
      "instrumenting <class 'tuple'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'llama_index.core.storage.docstore.types.RefDocInfo'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index.llms.groq.base.Groq'>\n",
      "\tinstrumenting stream\n",
      "\tinstrumenting astream\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index.llms.openai_like.base.OpenAILike'>\n",
      "\tinstrumenting stream\n",
      "\tinstrumenting astream\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "\tinstrumenting stream\n",
      "\tinstrumenting astream\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "\tinstrumenting stream\n",
      "\tinstrumenting astream\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "\tinstrumenting stream\n",
      "\tinstrumenting astream\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.groq.base.Groq'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "# Purana import (deprecated)\n",
    "# from trulens_eval import Tru, TruLlama\n",
    "\n",
    "# Naya import (v1.0+)\n",
    "from trulens.core import Tru\n",
    "from trulens.apps.llamaindex import TruLlama\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "tru_recorder = TruLlama(query_engine, app_id='Direct Query Engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>...</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>eval_cost</th>\n",
       "      <th>eval_cost_snowflake</th>\n",
       "      <th>cost_currency</th>\n",
       "      <th>num_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>{'app_name': 'Direct Query Engine', 'app_versi...</td>\n",
       "      <td>SPAN</td>\n",
       "      <td>6b1757ba-2b9e-44d7-b20f-152b44e07907</td>\n",
       "      <td></td>\n",
       "      <td>What are the technologies used in the project?</td>\n",
       "      <td>The technologies used in the project include M...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>{'n_tokens': 0, 'cost': 0.0}</td>\n",
       "      <td>{'start_time': 2026-01-15 20:46:53.652916, 'en...</td>\n",
       "      <td>2026-01-15 20:46:53.652916</td>\n",
       "      <td>0.700009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>{'app_name': 'Direct Query Engine', 'app_versi...</td>\n",
       "      <td>SPAN</td>\n",
       "      <td>3775e8dd-6d89-43a1-8e5c-84049df37800</td>\n",
       "      <td></td>\n",
       "      <td>What is the installation process?</td>\n",
       "      <td>The installation process involves installing t...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>{'n_tokens': 0, 'cost': 0.0}</td>\n",
       "      <td>{'start_time': 2026-01-15 20:46:54.352925, 'en...</td>\n",
       "      <td>2026-01-15 20:46:54.352925</td>\n",
       "      <td>0.342185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>{'app_name': 'Direct Query Engine', 'app_versi...</td>\n",
       "      <td>SPAN</td>\n",
       "      <td>01a80b26-1457-479c-aaf8-421f3a106698</td>\n",
       "      <td></td>\n",
       "      <td>Can you talk about the dataset used in the pro...</td>\n",
       "      <td>The dataset used in the project consists of ar...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>{'n_tokens': 0, 'cost': 0.0}</td>\n",
       "      <td>{'start_time': 2026-01-15 20:46:54.695110, 'en...</td>\n",
       "      <td>2026-01-15 20:46:54.695110</td>\n",
       "      <td>0.599921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>{'app_name': 'Direct Query Engine', 'app_versi...</td>\n",
       "      <td>SPAN</td>\n",
       "      <td>eaf05adc-80d0-407e-a78b-0be3ed15e034</td>\n",
       "      <td></td>\n",
       "      <td>Can you explain the usage of the project?</td>\n",
       "      <td>The usage of the project involves three main s...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>{'n_tokens': 0, 'cost': 0.0}</td>\n",
       "      <td>{'start_time': 2026-01-15 20:46:55.295031, 'en...</td>\n",
       "      <td>2026-01-15 20:46:55.295031</td>\n",
       "      <td>0.589804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>{'app_name': 'Direct Query Engine', 'app_versi...</td>\n",
       "      <td>SPAN</td>\n",
       "      <td>e00954ed-d466-45ad-a52a-443be916418e</td>\n",
       "      <td></td>\n",
       "      <td>What is the process of deployment used in the ...</td>\n",
       "      <td>The process of deployment used in the project ...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>{'n_tokens': 0, 'cost': 0.0}</td>\n",
       "      <td>{'start_time': 2026-01-15 20:46:55.884835, 'en...</td>\n",
       "      <td>2026-01-15 20:46:55.884835</td>\n",
       "      <td>0.512862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      app_id             app_name app_version  \\\n",
       "0  app_hash_6e8221fde876d15698298cea8c0d1bd6  Direct Query Engine        base   \n",
       "1  app_hash_6e8221fde876d15698298cea8c0d1bd6  Direct Query Engine        base   \n",
       "2  app_hash_6e8221fde876d15698298cea8c0d1bd6  Direct Query Engine        base   \n",
       "3  app_hash_6e8221fde876d15698298cea8c0d1bd6  Direct Query Engine        base   \n",
       "4  app_hash_6e8221fde876d15698298cea8c0d1bd6  Direct Query Engine        base   \n",
       "\n",
       "                                            app_json  type  \\\n",
       "0  {'app_name': 'Direct Query Engine', 'app_versi...  SPAN   \n",
       "1  {'app_name': 'Direct Query Engine', 'app_versi...  SPAN   \n",
       "2  {'app_name': 'Direct Query Engine', 'app_versi...  SPAN   \n",
       "3  {'app_name': 'Direct Query Engine', 'app_versi...  SPAN   \n",
       "4  {'app_name': 'Direct Query Engine', 'app_versi...  SPAN   \n",
       "\n",
       "                              record_id input_id  \\\n",
       "0  6b1757ba-2b9e-44d7-b20f-152b44e07907            \n",
       "1  3775e8dd-6d89-43a1-8e5c-84049df37800            \n",
       "2  01a80b26-1457-479c-aaf8-421f3a106698            \n",
       "3  eaf05adc-80d0-407e-a78b-0be3ed15e034            \n",
       "4  e00954ed-d466-45ad-a52a-443be916418e            \n",
       "\n",
       "                                               input  \\\n",
       "0     What are the technologies used in the project?   \n",
       "1                  What is the installation process?   \n",
       "2  Can you talk about the dataset used in the pro...   \n",
       "3          Can you explain the usage of the project?   \n",
       "4  What is the process of deployment used in the ...   \n",
       "\n",
       "                                              output tags  ...  \\\n",
       "0  The technologies used in the project include M...       ...   \n",
       "1  The installation process involves installing t...       ...   \n",
       "2  The dataset used in the project consists of ar...       ...   \n",
       "3  The usage of the project involves three main s...       ...   \n",
       "4  The process of deployment used in the project ...       ...   \n",
       "\n",
       "                      cost_json  \\\n",
       "0  {'n_tokens': 0, 'cost': 0.0}   \n",
       "1  {'n_tokens': 0, 'cost': 0.0}   \n",
       "2  {'n_tokens': 0, 'cost': 0.0}   \n",
       "3  {'n_tokens': 0, 'cost': 0.0}   \n",
       "4  {'n_tokens': 0, 'cost': 0.0}   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {'start_time': 2026-01-15 20:46:53.652916, 'en...   \n",
       "1  {'start_time': 2026-01-15 20:46:54.352925, 'en...   \n",
       "2  {'start_time': 2026-01-15 20:46:54.695110, 'en...   \n",
       "3  {'start_time': 2026-01-15 20:46:55.295031, 'en...   \n",
       "4  {'start_time': 2026-01-15 20:46:55.884835, 'en...   \n",
       "\n",
       "                          ts   latency  total_tokens  total_cost  eval_cost  \\\n",
       "0 2026-01-15 20:46:53.652916  0.700009             0         0.0        0.0   \n",
       "1 2026-01-15 20:46:54.352925  0.342185             0         0.0        0.0   \n",
       "2 2026-01-15 20:46:54.695110  0.599921             0         0.0        0.0   \n",
       "3 2026-01-15 20:46:55.295031  0.589804             0         0.0        0.0   \n",
       "4 2026-01-15 20:46:55.884835  0.512862             0         0.0        0.0   \n",
       "\n",
       "   eval_cost_snowflake  cost_currency num_events  \n",
       "0                  0.0            USD          8  \n",
       "1                  0.0            USD          8  \n",
       "2                  0.0            USD          8  \n",
       "3                  0.0            USD          8  \n",
       "4                  0.0            USD          8  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_4328\\1997498841.py:2: DeprecationWarning: Method `run_dashboard` has been renamed or moved to `trulens.dashboard.run.run_dashboard`.\n",
      "\n",
      "  tru.run_dashboard()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eee16dc78e940819200ae89139079be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
